{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.18.2)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2020.6.20)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (7.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib) (1.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib\n",
    "import  torch\n",
    "from    torch import nn, optim, autograd\n",
    "import  numpy as np\n",
    "from    torch.nn import functional as F\n",
    "from    matplotlib import pyplot as plt\n",
    "import  random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_dim = 400\n",
    "batchsz = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(2, h_dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(h_dim, h_dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(h_dim, h_dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(h_dim, 2),\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        output = self.net(z)\n",
    "        return output\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(2, h_dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(h_dim, h_dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(h_dim, h_dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(h_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.net(x)\n",
    "        return output.view(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator():\n",
    "\n",
    "    scale = 2.\n",
    "    centers = [\n",
    "        (1, 0),\n",
    "        (-1, 0),\n",
    "        (0, 1),\n",
    "        (0, -1),\n",
    "        (1. / np.sqrt(2), 1. / np.sqrt(2)),\n",
    "        (1. / np.sqrt(2), -1. / np.sqrt(2)),\n",
    "        (-1. / np.sqrt(2), 1. / np.sqrt(2)),\n",
    "        (-1. / np.sqrt(2), -1. / np.sqrt(2))\n",
    "    ]\n",
    "    centers = [(scale * x, scale * y) for x, y in centers]\n",
    "    while True:\n",
    "        dataset = []\n",
    "        for i in range(batchsz):\n",
    "            point = np.random.randn(2) * .02\n",
    "            center = random.choice(centers)\n",
    "            point[0] += center[0]\n",
    "            point[1] += center[1]\n",
    "            dataset.append(point)\n",
    "        dataset = np.array(dataset, dtype='float32')\n",
    "        dataset /= 1.414  # stdev\n",
    "        yield dataset\n",
    "\n",
    "    # for i in range(100000//25):\n",
    "    #     for x in range(-2, 3):\n",
    "    #         for y in range(-2, 3):\n",
    "    #             point = np.random.randn(2).astype(np.float32) * 0.05\n",
    "    #             point[0] += 2 * x\n",
    "    #             point[1] += 2 * y\n",
    "    #             dataset.append(point)\n",
    "    #\n",
    "    # dataset = np.array(dataset)\n",
    "    # print('dataset:', dataset.shape)\n",
    "    # viz.scatter(dataset, win='dataset', opts=dict(title='dataset', webgl=True))\n",
    "    #\n",
    "    # while True:\n",
    "    #     np.random.shuffle(dataset)\n",
    "    #\n",
    "    #     for i in range(len(dataset)//batchsz):\n",
    "    #         yield dataset[i*batchsz : (i+1)*batchsz]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        # m.weight.data.normal_(0.0, 0.02)\n",
    "        nn.init.kaiming_normal_(m.weight)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penalty(D, xr, xf):\n",
    "    \"\"\"\n",
    "    :param D:\n",
    "    :param xr:\n",
    "    :param xf:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    LAMBDA = 0.3\n",
    "\n",
    "    # only constrait for Discriminator\n",
    "    xf = xf.detach()\n",
    "    xr = xr.detach()\n",
    "\n",
    "    # [b, 1] => [b, 2]\n",
    "    alpha = torch.rand(batchsz, 1).cuda()\n",
    "    alpha = alpha.expand_as(xr)\n",
    "\n",
    "    interpolates = alpha * xr + ((1 - alpha) * xf)\n",
    "    interpolates.requires_grad_()\n",
    "\n",
    "    disc_interpolates = D(interpolates)\n",
    "\n",
    "    gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n",
    "                              grad_outputs=torch.ones_like(disc_interpolates),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "\n",
    "    gp = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * LAMBDA\n",
    "\n",
    "    return gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    torch.manual_seed(23)\n",
    "    np.random.seed(23)\n",
    "\n",
    "    G = Generator().cuda()\n",
    "    D = Discriminator().cuda()\n",
    "    G.apply(weights_init)\n",
    "    D.apply(weights_init)\n",
    "\n",
    "    optim_G = optim.Adam(G.parameters(), lr=1e-3, betas=(0.5, 0.9))\n",
    "    optim_D = optim.Adam(D.parameters(), lr=1e-3, betas=(0.5, 0.9))\n",
    "\n",
    "\n",
    "    data_iter = data_generator()\n",
    "    print('batch:', next(data_iter).shape)\n",
    "    for epoch in range(50000):\n",
    "\n",
    "        # 1. train discriminator for k steps\n",
    "        for _ in range(5):\n",
    "            x = next(data_iter)\n",
    "            xr = torch.from_numpy(x).cuda()\n",
    "\n",
    "            # [b]\n",
    "            predr = (D(xr))\n",
    "            # max log(lossr)\n",
    "            lossr = - (predr.mean())\n",
    "\n",
    "            # [b, 2]\n",
    "            z = torch.randn(batchsz, 2).cuda()\n",
    "            # stop gradient on G\n",
    "            # [b, 2]\n",
    "            xf = G(z).detach()\n",
    "            # [b]\n",
    "            predf = (D(xf))\n",
    "            # min predf\n",
    "            lossf = (predf.mean())\n",
    "\n",
    "            # gradient penalty\n",
    "            gp = gradient_penalty(D, xr, xf)\n",
    "\n",
    "            loss_D = lossr + lossf + gp\n",
    "            optim_D.zero_grad()\n",
    "            loss_D.backward()\n",
    "            # for p in D.parameters():\n",
    "            #     print(p.grad.norm())\n",
    "            optim_D.step()\n",
    "\n",
    "\n",
    "        # 2. train Generator\n",
    "        z = torch.randn(batchsz, 2).cuda()\n",
    "        xf = G(z)\n",
    "        predf = (D(xf))\n",
    "        # max predf\n",
    "        loss_G = - (predf.mean())\n",
    "        optim_G.zero_grad()\n",
    "        loss_G.backward()\n",
    "        optim_G.step()\n",
    "        if epoch % 100 == 0:\n",
    "\n",
    "\n",
    "            print(loss_D.item(), loss_G.item())\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: (512, 2)\n",
      "-0.1235349178314209 -0.4735383689403534\n",
      "-0.4824652671813965 -0.19732406735420227\n",
      "-0.46247702836990356 -0.31346970796585083\n",
      "-0.21293586492538452 -0.4524286091327667\n",
      "-0.23654669523239136 -0.4979023337364197\n",
      "-0.1441769301891327 -0.5980746746063232\n",
      "-0.09675592184066772 -0.589372992515564\n",
      "-0.0715830847620964 -0.6962414979934692\n",
      "-0.07945317775011063 -0.6900238990783691\n",
      "-0.06443130970001221 -0.6662106513977051\n",
      "-0.10740194469690323 -0.4989456832408905\n",
      "-0.10883487015962601 -0.615113377571106\n",
      "-0.07567507028579712 -0.6126163005828857\n",
      "-0.0844583660364151 -0.5428880453109741\n",
      "-0.04609978199005127 -0.6910769939422607\n",
      "-0.055066827684640884 -0.6646562218666077\n",
      "-0.051971375942230225 -0.5648796558380127\n",
      "-0.05280163139104843 -0.6135662794113159\n",
      "-0.030006330460309982 -0.7168947458267212\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-0275ef2024fe>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# 1. train discriminator for k steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mxr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-4730f10a083b>\u001b[0m in \u001b[0;36mdata_generator\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatchsz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m.02\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mcenter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcenters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcenter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
